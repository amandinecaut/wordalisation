"""
Entrypoint for streamlit app.
Runs top to bottom every time the user interacts with the app (other than imports and cached functions).
"""

# Library imports
import traceback
import copy

import streamlit as st


from utils.page_components import (
    add_common_page_elements,
)


# def show():
sidebar_container = add_common_page_elements()
page_container = st.sidebar.container()
sidebar_container = st.sidebar.container()

st.divider()

displaytext = """## About GPT Educational """

st.markdown(displaytext)

displaytext = (
   """
   GPT Educational is a basic retrieval-augmented chatbot framework designed to generate detailed reports about data. The system is built to provide users with the flexibility to create bots that can effectively discuss and interpret data in various contexts.

This repository contains three applications: the Football Scout application, the Personality GPT application, and the International Survey application.

The Football Scout application presents a bot that can describe players who played as strikers for at least 300 minutes in the Premier League during the 2017-18 season. The application allows users to obtain descriptions of these players compared to others based on several performance metrics and provides the ability to ask specific questions about individual players. 

The Personality GPT application focuses on personality test data, generating "wordalisations" that describe individuals based on their answers to a personality test. 

The International Survey application generates detailed reports about countries based on data derived from the World Value Survey (WVS). It illustrates the wordalisation method by comparing a country's scores across six social factors to their relative positions within the global distribution of scores. The app, implemented within the GPT Educational framework, serves as an example to guide others in building similar tools. 

## Usage

This application was made with Streamlit.  To run locally, first create .streamlit/secrets.toml with keys, etc... then run:
```bash
conda create --name streamlit_env
conda activate streamlit_env
pip install -r requirements.txt
streamlit run app.py
```
Once you have made changes to the code, save, move focus to the streamlit tab, then press c to clear caches if necessary, then r to rerun. 

You also need to have access to GPT API to use this package. Alternatively, you need access to Gemini API but that requires changes to the [.streamlit/secrets.toml](.streamlit/secrets.toml) file (see below).

## How does it work?
### App
Streamlit reruns the code every time the user interacts with the app. This code is located in app.py. The user selects a player and the visual and word report starts to generate.

The application builds primarily around five classes: data_sources, visual, description, chat and embeddings. We now describe these in turn.

### Data sources

The code data_sources.py consists of three classes:

**class Data()**: Gets, processes and manage various forms of data. The data is primarily stored in data.df
**class Stats(Data)**: Calculates z-scores, ranks and pct_ranks, adding these to stats.df

While the above classes can be adapted to any data source, the last class is specifically for football player data.

**class PlayerStats(Stats)**: Loads in a dataframe of statistics about forwards. The data is loaded in from data/events/Forwards.csv. This data is in turn generated by saving a dataframe from the following tutorial about scouting: https://soccermatics.readthedocs.io/en/latest/gallery/lesson3/plot_RadarPlot.html

It provided the following statistics: Non-penalty goals, Assists, Key passes, Smart passes, Ariel duels won, Ground attacking duels won, Non-penalty expected goals, Passes ending in final third, Receptions in final third for players in the Premier League 2017/18 season.

### Visual

There is quite a lot of code here, but it is primarily about making nice visuals. Of particular interest our **add_player(...)** and **add_players(...)** which add the focal player and compare him to the other players in the data.

### Description

It is in this part of the code where we start doing something novel. The three most important functions for creating a text are:

**get_intro_messages()**: This sets up the bot and explains to it what it does.
**synthesize_text()**: This converts the stats.df to a description in words of what the data says.
**get_prompt_messages()**: This is the prompt which tells GPT3 or GPT4 how to use the texts supplied.

A key to success of prompting lies in two types of files, known as describe and gpt_example files. These are given for this application in 
data/describe/Forward
and
data/gpt_examples/Forward

By clicking on the expander in the Description messages you can see how they have been used to construct a prompt to GPT4. It is this prompt which then generates the text under the figure.

### Chat

The chat also utilises prompting of GPT to allow user questions to be answered. This is the bot.

The key function here is **handle_input(input)** which puts together a query combining:

1, An instruction for the bot, which set up by **instruction_messages()**.
2, The previous conversation
3, And relevant information about the player and for answering the questuon, from  **get_relevant_info(input)**.

The get_relevant_info(input) both retrieves the synthesize_text() from the description and searches a library of embedded questions to find relevant info. To do this the input is embedded in order to search the database of embedded questions for relevant entries. 

### Embeddings

Certain files in /data/describe/ contain question-answer pairs that are embedded by pages/embedder.py. You can run this app by clicking on 'Embedding Tool' in top left corner of the app. This is then used to search (using cosine similarity) for the best question-answer pairs for answering the users query.


### Using Open AI API
To use Open AI you need a API key. Then you need to add the following lines to your [.streamlit/secrets.toml](.streamlit/secrets.toml) file.

```
USE_GEMINI = false
GPT_BASE = "address of you deployment of Chat GPT"
GPT_VERSION = "version date"
GPT_KEY = "your key"
GPT_ENGINE = "model name"
```

### Using Gemini API
If, instead of using OpenAI's API, you want to use Google's. You need to add the following lines to your [.streamlit/secrets.toml](.streamlit/secrets.toml) file.

```
USE_GEMINI = true
GEMINI_API_KEY = "YOUR_API_KEY"

# Can use any chat model
GEMINI_CHAT_MODEL = "gemini-1.5-flash"

# Can use any embedding model
GEMINI_EMBEDDING_MODEL = "models/text-embedding-004"
```

   """
)

st.markdown(displaytext)
